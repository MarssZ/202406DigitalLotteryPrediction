{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 版本： 3.8.18\n",
      "TensorFlow 版本： 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print(\"Python 版本：\", platform.python_version())\n",
    "print(\"TensorFlow 版本：\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CE58931310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "[[0.9846842 ]\n",
      " [0.9775135 ]\n",
      " [0.08918948]\n",
      " [0.04530678]\n",
      " [0.04281044]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 训练最终模型的示例\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets._samples_generator import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "## 生成 2 维分类数据集\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)  # 生成 100 个样本，2 个聚类中心，2 个特征的数据集，并将特征和标签分别存储在 `X` 和 `y` 中\n",
    "\n",
    "scalar = MinMaxScaler()  # 创建 `MinMaxScaler` 对象\n",
    "scalar.fit(X)  # 对 `X` 进行拟合\n",
    "X = scalar.transform(X)  # 对 `X` 进行缩放\n",
    "\n",
    "## 定义并拟合最终模型\n",
    "model = Sequential()  # 创建顺序模型对象\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))  # 添加具有 4 个神经元、输入维度为 2 且激活函数为 `relu` 的隐藏层\n",
    "model.add(Dense(4, activation='relu'))  # 添加具有 4 个神经元且激活函数为 `relu` 的隐藏层\n",
    "model.add(Dense(1, activation='sigmoid'))  # 添加具有 1 个神经元且激活函数为 `sigmoid` 的输出层\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')  # 使用 `binary_crossentropy` 损失函数和 `adam` 优化器编译模型\n",
    "model.fit(X, y, epochs=200, verbose=0)  # 使用缩放后的 `X` 和 `y` 训练模型，训练轮数为 200 次，`verbose=0` 表示不输出训练过程的详细信息\n",
    "\n",
    "# 不知分类结果的新的实例\n",
    "Xnew, _ = make_blobs(n_samples=20, centers=2, n_features=2, random_state=1)\n",
    "Xnew = scalar.transform(Xnew)\n",
    "\n",
    "# 使用模型进行预测，得到概率数组\n",
    "predictions = model.predict(Xnew)\n",
    "print(predictions[:5])\n",
    "\n",
    "# 使用 np.argmax 获取概率最高的类别索引\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "# show the inputs and predicted outputs\n",
    "print(predicted_classes[:5])\n",
    "# for i in range(len(predicted_classes)):\n",
    "# \tprint(\"X=%s, Predicted=%s\" % (Xnew[i], predicted_classes[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
